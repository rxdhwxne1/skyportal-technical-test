import json
from datetime import datetime
import streamlit as st
import ollama
import random

# Fictif names list
NAMES = ["Stephen Curry", "Lebron James", "Victor Wembanyama", "Kevin Durant", "James Harden", "Jason Tatum", "Kyrie Irving", "Jon Jones", "Stipe Miocic", "Khabib Nurmagomedov", "Conor McGregor", "Kamaru Usman"]

# Dictionnary to store author_id -> author_name associations
AUTHOR_ID_TO_NAME = {}

def generate_fake_name():
    return f"{random.choice(NAMES)}"

def create_author_mapping(data):
    author_ids = set()

    for obj in data['data']['sources']:
        for source in obj.get('comments', []) + obj.get('classifications', []):
            author_id = source.get('author_id')
            author_name = source.get('author_name')
            
            if author_id:
                author_ids.add(author_id)
            
            if author_name and author_id not in AUTHOR_ID_TO_NAME:
                AUTHOR_ID_TO_NAME[author_id] = author_name

    for author_id in author_ids:
        if author_id not in AUTHOR_ID_TO_NAME:
            AUTHOR_ID_TO_NAME[author_id] = generate_fake_name()

    return AUTHOR_ID_TO_NAME

# Load the JSON file
with open('rcf_sample_sources.json', 'r') as file:
    data = json.load(file)

# Create the author mapping
AUTHOR_ID_TO_NAME = create_author_mapping(data)

# Extract unique group names
unique_groups = list(set(group['name'] for obj in data['data']['sources'] for group in obj['groups']))

# Function to clean and prepare data
def clean_data(obj):
    # Find most recent redshift value
    if obj.get('redshift_history'):
        latest_redshift = max(
            obj['redshift_history'],
            key=lambda x: datetime.fromisoformat(x['set_at_utc'].replace('Z', ''))
        )
        redshift_value = latest_redshift['value']
    else:
        redshift_value = obj.get('redshift', None)

    # Mark the classifications generated by ML
    classifications = [
        {
            'classification': c['classification'],
            'probability': c.get('probability', None),
            'created_at': c['created_at'],
            'author_name': AUTHOR_ID_TO_NAME.get(c.get('author_id'), 'Unknown'),
            'ml_generated': c['ml']
        }
        for c in obj.get('classifications', [])
    ]

    # Mark the comments generated by bots
    comments = [
        {
            'author_id': c['author_id'],
            'text': c['text'],
            'created_at': c['created_at'],
            'bot_generated': c['bot'],
            'author_name': AUTHOR_ID_TO_NAME.get(c['author_id'], 'Unknown')
        }
        for c in obj.get('comments', [])
    ]

    cleaned_obj = {
        'id': obj['id'],
        'RA/Dec': f"{obj['ra']}, {obj['dec']}",
        'redshift': redshift_value,
        'tns_name': obj.get('tns_name', 'N/A'),
        'classifications': classifications,
        'comments': comments,
        'groups': [group['name'] for group in obj['groups']],
        'host': obj.get('host', 'Unknown'),
        'host_offset': obj.get('host_offset', 'N/A'),
        'gal_lon': obj.get('gal_lon', None),
        'gal_lat': obj.get('gal_lat', None),
        'luminosity_distance': obj.get('luminosity_distance', 'N/A'),
        'dm': obj.get('dm', 'N/A'),
        'angular_diameter_distance': obj.get('angular_diameter_distance', 'N/A'),
        'thumbnails': [thumbnail['public_url'] for thumbnail in obj.get('thumbnails', [])]
    }

    return cleaned_obj

# Clean the data for all objects
cleaned_objects = [clean_data(obj) for obj in data['data']['sources']]

# Function to create a prompt for Ollama
def create_prompt(obj):
    classifications_str = ', '.join([
        f"{c['classification']} (ML-generated)" if c['ml_generated'] else f"{c['classification']} by {c['author_name']}"
        for c in obj['classifications']
    ]) if obj['classifications'] else 'None'

    comments_str = ', '.join([
        f"{comment['text']} (Bot-generated)" if comment['bot_generated'] else f"{comment['text']} by {comment['author_name']}"
        for comment in obj['comments'] if comment['text']
    ]) if obj['comments'] else 'None'

    data_block = f"""
    Object ID: {obj['id']}
    Object Name: {obj['tns_name'] or 'N/A'}
    Position: {obj['RA/Dec']}
    Redshift: {obj['redshift'] or 'None'}
    Luminosity Distance: {obj['luminosity_distance'] or 'N/A'}
    Classification: {classifications_str}
    Key Comments: {comments_str}
    Thumbnail URLs: {', '.join(obj['thumbnails']) if obj['thumbnails'] else 'None'}
    """

    prompt = f"""
    For astronomical transients from 16/05/2021:
    Report for the object:
    1. Name and ID
    2. Position: RA/Dec (format: RA: / Dec: )
    3. Redshift and Luminosity Distance
    4. Key observations and spectra obtained
    5. Notable comments with author attribution [Author Name], limited to 1-2 sentences summarizing key insights
    6. Bot/ML classifications marked as [Bot/ML-generated]
    7. Thumbnail URL
    
    If comments and classifications share the same timestamp, group them and indicate the association.
    Limit the response to the data provided, using professional astronomical notation.
    Use professional astronomical notation.
    Format the report concisely and in the above structure.

    Data: {data_block}
    """
    return prompt

# Function to generate a summary using Ollama
def generate_summary(prompt):
    try:
        response = ollama.chat(
            model="llama3.2",
            messages=[{"role": "user", "content": prompt}],
        )
        return response['message']['content']
    except Exception as e:
        return f"Error generating summary: {e}"

# Initialisation of the summaries set in session_state
if 'summaries' not in st.session_state:
    st.session_state.summaries = set()

# Streamlit interface
st.title("Daily Summaries of Astronomical Actions")
st.write("Select a group and an object by TNS Name to view the summary.")

# Add dropdown to select a group
selected_group = st.selectbox("Select a group", unique_groups)

# Filter objects based on selected group
filtered_objects = [obj for obj in cleaned_objects if selected_group in obj['groups']]

# Add dropdown to select an object by TNS Name
tns_names = [obj['tns_name'] for obj in filtered_objects if obj['tns_name'] != 'N/A']
selected_tns_name = st.selectbox("Select an object by TNS Name", tns_names)

validate_button = st.button("Generate Summary")

# Generate the summary if the button is clicked
if validate_button:
    selected_obj = next((obj for obj in filtered_objects if obj['tns_name'] == selected_tns_name), None)
    if selected_obj:
        with st.spinner("Generating summary..."):
            prompt = create_prompt(selected_obj)
            summary = generate_summary(prompt)
            
            # Add the summary to the set in session_state
            st.session_state.summaries.add(f"Summary for {selected_tns_name}:\n{summary}")
            
            st.success("Summary generated successfully!")
    else:
        st.write("Selected object not found.")


if st.session_state.summaries:
    st.subheader("Previously Generated Summaries")
    summary_titles = [summary.split("\n")[0].replace("Summary for ", "") for summary in st.session_state.summaries]

    selected_summary_title = st.selectbox("Select a summary to view", summary_titles)

    # Display the selected summary
    selected_summary = next(
        (summary for summary in st.session_state.summaries if f"Summary for {selected_summary_title}" in summary),
        None
    )
    if selected_summary:
        st.write(selected_summary)
