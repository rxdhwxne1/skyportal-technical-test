import json
from datetime import datetime
import time
import streamlit as st
import ollama
import random

# Fictif names list
NAMES = ["S.Curry (generated name)", "L.James (generated name)", "V.Wembanyama (generated name)",
         "K.Durant (generated name)", "J.Harden (generated name)", "J.Tatum (generated name)",
         "K.Irving (generated name)", "J.Jones (generated name)", "S.Miocic (generated name)",
         "K.Nurmagomedov (generated name)", "C.McGregor (generated name)", "K.Usman (generated name)"]

# Dictionnary to store author_id -> author_name associations
AUTHOR_ID_TO_NAME = {}

def generate_fake_name():
    return f"{random.choice(NAMES)}"

def create_author_mapping(data):
    author_ids = set()

    for obj in data['data']['sources']:
        for source in obj.get('comments', []) + obj.get('classifications', []):
            author_id = source.get('author_id')
            author_name = source.get('author_name')
            if author_id:
                author_ids.add(author_id)
            if author_name and author_id not in AUTHOR_ID_TO_NAME:
                AUTHOR_ID_TO_NAME[author_id] = author_name
    for author_id in author_ids:
        if author_id not in AUTHOR_ID_TO_NAME:
            AUTHOR_ID_TO_NAME[author_id] = generate_fake_name()
    return AUTHOR_ID_TO_NAME

# Load the JSON file
with open('rcf_sample_sources.json', 'r') as file:
    data = json.load(file)

# Create the author mapping
AUTHOR_ID_TO_NAME = create_author_mapping(data)

# Extract unique group names
unique_groups = list(set(group['name'] for obj in data['data']['sources'] for group in obj['groups']))

# Function to clean and prepare data
def clean_data(obj):
    if obj.get('redshift_history'):
        latest_redshift = max(
            obj['redshift_history'],
            key=lambda x: datetime.fromisoformat(x['set_at_utc'].replace('Z', ''))
        )
        redshift_value = latest_redshift['value']
    else:
        redshift_value = obj.get('redshift', None)

    classifications = [
        {
            'classification': c['classification'],
            'probability': c.get('probability', None),
            'created_at': c['created_at'],
            'author_name': AUTHOR_ID_TO_NAME.get(c.get('author_id'), 'Unknown'),
            'ml_generated': c['ml']
        }
        for c in obj.get('classifications', [])
    ]

    comments = [
        {
            'author_id': c['author_id'],
            'text': c['text'],
            'created_at': c['created_at'],
            'bot_generated': c['bot'],
            'author_name': AUTHOR_ID_TO_NAME.get(c['author_id'], 'Unknown')
        }
        for c in obj.get('comments', [])
    ]

    cleaned_obj = {
        'id': obj['id'],
        'RA/Dec': f"{obj['ra']}, {obj['dec']}",
        'redshift': redshift_value,
        'tns_name': obj.get('tns_name', 'N/A'),
        'classifications': classifications,
        'comments': comments,
        'groups': [group['name'] for group in obj['groups']],
        'luminosity_distance': obj.get('luminosity_distance', 'N/A'),
        'thumbnails': [thumbnail['public_url'] for thumbnail in obj.get('thumbnails', [])]
    }
    return cleaned_obj

# Clean the data for all objects
cleaned_objects = [clean_data(obj) for obj in data['data']['sources']]

# Streamlit interface
st.title("Daily Summaries of Astronomical Actions")

# Step 1: User defines the structure of the summary
st.subheader("Step 1: Define Summary Structure")
structure = st.text_area(
    "Enter the structure you want Ollama to follow for generating the summary:",
    height=200,
    value='''Object Name:
       [Object Name]

    Position (RA/Dec):
        [RA/Dec values]

    Redshift:
        [Redshift value, or "None" if unavailable]

    Classifications:
        [Classification Name] (by [Author Name] OR [ML-generated] if applicable)

    Key Comments:
        [Comment Text] (by [Author Name] OR [Bot-generated] if applicable)

    Thumbnail Links:
        [list of URLs]

    Guidelines for Generation:
    1. Data Integrity: Ensure that all data provided is strictly preserved. Do not modify or infer additional information. Timestamps, values, and names must remain exactly as provided.

    2. Scientific Notation: Use standard astronomical terminology and formatting, including proper units and notations, to ensure clarity and consistency for a professional audience.

    3. Data Provenance: Explicitly state whether the classification or comment was generated by a human author, a bot, or a machine learning pipeline (e.g., "ML-generated" or "Bot-generated").

    4. Contextual Relevance: If multiple comments or classifications share the same timestamp, clearly link them to indicate their contextual relationship and relevance.

    5. Clarity and Brevity: The summary should be concise, yet comprehensive. Avoid unnecessary details while ensuring that key scientific information is fully captured.

    6. Comment/Classification History: If there are multiple comments or classifications for the same object, provide a list of all contributions, ordered by their timestamp.

    7. Thumbnail URLs: List each available URL as a bullet point. Ensure that each URL is on its own line for clear separation.'''
    )

configure_structure = st.button("Configure Structure")

if configure_structure:
    if structure.strip():
        st.session_state.structure = structure
        with st.spinner("Configuring structure with Ollama..."):
            ollama.chat(
                model="llama3.2:1b",
                messages=[{"role": "user", "content": f"Generate a summary using this structure:\n{structure}"}]
            )
        st.success("Structure configured successfully!")
    else:
        st.error("Please enter a valid structure.")

# Step 2: Generate Summary for a Specific Object
st.subheader("Step 2: Generate Summary for a Specific Object")

if "summaries" not in st.session_state:
    st.session_state["summaries"] = {}

if "structure" in st.session_state:
    selected_group = st.selectbox("Select a group", unique_groups)
    filtered_objects = [obj for obj in cleaned_objects if selected_group in obj['groups']]
    tns_names = [obj['tns_name'] for obj in filtered_objects if obj['tns_name'] != 'N/A']
    selected_tns_name = st.selectbox("Select an object by TNS Name", tns_names)

    generate_summary_button = st.button("Generate Summary for Selected Object")

    if generate_summary_button:
        selected_obj = next((obj for obj in filtered_objects if obj['tns_name'] == selected_tns_name), None)
        if selected_obj:
            with st.spinner("Generating summary..."):
                prompt = f"Here is the data for the transient object:\n{selected_obj}\nGenerate the summary using the configured structure."
                start = time.time()
                response = ollama.chat(
                    model="llama3.2:1b",
                    messages=[{"role": "user", "content": prompt}]
                )
                st.session_state.summaries[selected_tns_name] = response['message']['content']
                end = time.time()
                st.write(f"Summary generated in {end - start:.2f} seconds.")
                st.success(f"Summary for {selected_tns_name} generated successfully!")
else:
    st.warning("Please configure the structure first.")

# Display previously generated summaries
if st.session_state.get("summaries"):
    st.subheader("View Summaries")

    # Select summary to view or option to view all
    summary_titles = list(st.session_state.summaries.keys())
    summary_titles.insert(0, "All Summaries")
    selected_summary_title = st.selectbox("Select a summary to view", summary_titles)

    display_summary_button = st.button("Display Selected Summary")

    if display_summary_button:
        if selected_summary_title == "All Summaries":
            st.subheader("All Summaries")
            for tns_name, summary in st.session_state.summaries.items():
                st.write(f"### Summary for {tns_name}")
                st.write(summary)
        else:
            st.subheader(f"Summary for {selected_summary_title}")
            st.write(st.session_state.summaries[selected_summary_title])
