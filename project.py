import json
from datetime import datetime
import streamlit as st
import ollama
import random

# Fictif names list
NAMES = ["S.Curry (generated name)", "L.James (generated name)", "V.Wembanyama (generated name)",
         "K.Durant (generated name)", "J.Harden (generated name)", "J.Tatum (generated name)",
         "K.Irving (generated name)", "J.Jones (generated name)", "S.Miocic (generated name)",
         "K.Nurmagomedov (generated name)", "C.McGregor (generated name)", "K.Usman (generated name)"]

# Dictionnary to store author_id -> author_name associations
AUTHOR_ID_TO_NAME = {}

def generate_fake_name():
    return f"{random.choice(NAMES)}"

def create_author_mapping(data):
    author_ids = set()

    for obj in data['data']['sources']:
        for source in obj.get('comments', []) + obj.get('classifications', []):
            author_id = source.get('author_id')
            author_name = source.get('author_name')
            if author_id:
                author_ids.add(author_id)
            if author_name and author_id not in AUTHOR_ID_TO_NAME:
                AUTHOR_ID_TO_NAME[author_id] = author_name
    for author_id in author_ids:
        if author_id not in AUTHOR_ID_TO_NAME:
            AUTHOR_ID_TO_NAME[author_id] = generate_fake_name()
    return AUTHOR_ID_TO_NAME

# Load the JSON file
with open('rcf_sample_sources.json', 'r') as file:
    data = json.load(file)

# Create the author mapping
AUTHOR_ID_TO_NAME = create_author_mapping(data)

# Extract unique group names
unique_groups = list(set(group['name'] for obj in data['data']['sources'] for group in obj['groups']))

# Function to clean and prepare data
def clean_data(obj):
    # Find most recent redshift value
    if obj.get('redshift_history'):
        latest_redshift = max(
            obj['redshift_history'],
            key=lambda x: datetime.fromisoformat(x['set_at_utc'].replace('Z', ''))
        )
        redshift_value = latest_redshift['value']
    else:
        redshift_value = obj.get('redshift', None)

    # Mark the classifications generated by ML
    classifications = [
        {
            'classification': c['classification'],
            'probability': c.get('probability', None),
            'created_at': c['created_at'],
            'author_name': AUTHOR_ID_TO_NAME.get(c.get('author_id'), 'Unknown'),
            'ml_generated': c['ml']
        }
        for c in obj.get('classifications', [])
    ]

    # Mark the comments generated by bots
    comments = [
        {
            'author_id': c['author_id'],
            'text': c['text'],
            'created_at': c['created_at'],
            'bot_generated': c['bot'],
            'author_name': AUTHOR_ID_TO_NAME.get(c['author_id'], 'Unknown')
        }
        for c in obj.get('comments', [])
    ]

    cleaned_obj = {
        'id': obj['id'],
        'RA/Dec': f"{obj['ra']}, {obj['dec']}",
        'redshift': redshift_value,
        'tns_name': obj.get('tns_name', 'N/A'),
        'classifications': classifications,
        'comments': comments,
        'groups': [group['name'] for group in obj['groups']],
        'luminosity_distance': obj.get('luminosity_distance', 'N/A'),
        'thumbnails': [thumbnail['public_url'] for thumbnail in obj.get('thumbnails', [])]
    }

    return cleaned_obj

# Clean the data for all objects
cleaned_objects = [clean_data(obj) for obj in data['data']['sources']]

# Function to create a prompt for Ollama
def create_prompt(obj):
    classifications_str = ', '.join([
        f"{c['classification']} (ML-generated)" if c['ml_generated'] else f"{c['classification']} by {c['author_name']}"
        for c in obj['classifications']
    ]) if obj['classifications'] else 'None'

    comments_str = ', '.join([
        f"{comment['text']} (Bot-generated)" if comment['bot_generated'] else f"{comment['text']} by {comment['author_name']}"
        for comment in obj['comments'] if comment['text']
    ]) if obj['comments'] else 'None'

    data_block = f"""
    Object Name: {obj['tns_name'] or 'N/A'}
    Position: {obj['RA/Dec']}
    Redshift: {obj['redshift'] or 'None'}
    Luminosity Distance: {obj['luminosity_distance'] or 'N/A'}
    Classification: {classifications_str}
    Key Comments: {comments_str}
    Thumbnail URLs: {', '.join(obj['thumbnails']) if obj['thumbnails'] else 'None'}
    """

    prompt = f"""
    Using ONLY the data provided, generate a structured scientific summary for astronomers about the object and its recent actions. 
    Follow the format and guidelines below to ensure clarity and consistency with standard astronomical reporting:
    1. Data Integrity: Do not modify or infer any information beyond what is explicitly provided. All timestamps, values, and names must remain unchanged.
    2. Scientific Notation: Use standard astronomical terminology and notation to ensure readability for a professional audience.

    Structure for the summary:
    Object Name:
    [Object Name]

    Position (RA/Dec):
    [RA/Dec values]

    Redshift:
    [Redshift value, or "None" if unavailable]

    3. Highlight Data Provenance: Clearly identify whether data (e.g., classifications or comments) was generated by humans, bots, or ML pipelines.
    4. Contextual Relevance: If classifications and comments share a timestamp, link them to highlight potential contextual relationships.
    Classifications:
    - [Classification Name] (by [Author Name] OR [ML-generated] if applicable)

    Key Comments, if an author made multiple comments, list them in chronological order:
    - [Comment Text] (by [Author Name] OR [Bot-generated] if applicable)  

    5. Thumbnail URLs: Provide all available URLs in a bullet-point list with newlines between each URL.
    Thumbnail Links -> Mandatory if available:
    - [list of URLs]

    ---

    6. Brevity and Clarity: Keep the summary concise while ensuring it remains scientifically comprehensive. 
    Data: {data_block} 
    """
    return prompt

# Function to generate a summary using Ollama
def generate_summary(prompt):
    try:
        response = ollama.chat(
            model="llama3.2:1b",
            messages=[{"role": "user", "content": prompt}],
        )
        return response['message']['content']
    except Exception as e:
        return f"Error generating summary: {e}"

# Initialisation of the summaries set in session_state
if "summaries" not in st.session_state:
    st.session_state.summaries = {}

# Streamlit interface
st.title("Daily Summaries of Astronomical Actions")
st.write("Select a group and an object by TNS Name to view the summary.")

# Add dropdown to select a group
selected_group = st.selectbox("Select a group", unique_groups)

# Filter objects based on selected group
filtered_objects = [obj for obj in cleaned_objects if selected_group in obj['groups']]

# Add dropdown to select an object by TNS Name
tns_names = [obj['tns_name'] for obj in filtered_objects if obj['tns_name'] != 'N/A']
selected_tns_name = st.selectbox("Select an object by TNS Name", tns_names)

validate_button = st.button("Generate Summary")

import time

# Generate the summary if the button is clicked
if validate_button:
    selected_obj = next((obj for obj in filtered_objects if obj['tns_name'] == selected_tns_name), None)
    if selected_obj:
        with st.spinner("Generating summary..."):
            start = time.time()
            prompt = create_prompt(selected_obj)
            summary = generate_summary(prompt)

            end = time.time()
            # Add or update the summary in the session_state dictionary
            st.session_state.summaries[selected_tns_name] = f"Summary for {selected_tns_name}:\n{summary}"
            st.write(f"Summary generated in {end - start:.2f} seconds.")
            st.success("Summary generated successfully!")
    else:
        st.write("Selected object not found.")

if st.session_state.summaries:
    st.subheader("Previously Generated Summaries")
    summary_titles = list(st.session_state.summaries.keys())  # Get all object names
    selected_summary_title = st.selectbox("Select a summary to view", summary_titles)
    # Display the selected summary
    selected_summary = st.session_state.summaries[selected_summary_title]
    display_summary = st.button("Display Selected Summary")
    if display_summary:
        st.write(selected_summary)
        stop_display = st.button("Stop Display")
        if stop_display:
            st.empty()
    # display all summaries
    display_all = st.button("Display All Summaries")
    if display_all:
        st.subheader("All Summaries")
        for resume in st.session_state.summaries:
            st.write(st.session_state.summaries[resume])
            st.markdown("---")