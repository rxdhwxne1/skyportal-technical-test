import json
from datetime import datetime
import streamlit as st
import ollama
import random

# Fictif names list
NAMES = ["S.Curry (generated name)", "L.James (generated name)", "V.Wembanyama (generated name)",
         "K.Durant (generated name)", "J.Harden (generated name)", "J.Tatum (generated name)",
         "K.Irving (generated name)", "J.Jones (generated name)", "S.Miocic (generated name)",
         "K.Nurmagomedov (generated name)", "C.McGregor (generated name)", "K.Usman (generated name)"]

# Dictionnary to store author_id -> author_name associations
AUTHOR_ID_TO_NAME = {}

def generate_fake_name():
    return f"{random.choice(NAMES)}"

def create_author_mapping(data):
    author_ids = set()

    for obj in data['data']['sources']:
        for source in obj.get('comments', []) + obj.get('classifications', []):
            author_id = source.get('author_id')
            author_name = source.get('author_name')
            if author_id:
                author_ids.add(author_id)
            if author_name and author_id not in AUTHOR_ID_TO_NAME:
                AUTHOR_ID_TO_NAME[author_id] = author_name
    for author_id in author_ids:
        if author_id not in AUTHOR_ID_TO_NAME:
            AUTHOR_ID_TO_NAME[author_id] = generate_fake_name()
    return AUTHOR_ID_TO_NAME

# Load the JSON file
with open('rcf_sample_sources.json', 'r') as file:
    data = json.load(file)

# Create the author mapping
AUTHOR_ID_TO_NAME = create_author_mapping(data)

# Extract unique group names
unique_groups = list(set(group['name'] for obj in data['data']['sources'] for group in obj['groups']))

# Function to clean and prepare data
def clean_data(obj):
    # Find most recent redshift value
    if obj.get('redshift_history'):
        latest_redshift = max(
            obj['redshift_history'],
            key=lambda x: datetime.fromisoformat(x['set_at_utc'].replace('Z', ''))
        )
        redshift_value = latest_redshift['value']
    else:
        redshift_value = obj.get('redshift', None)

    # Mark the classifications generated by ML
    classifications = [
        {
            'classification': c['classification'],
            'probability': c.get('probability', None),
            'created_at': c['created_at'],
            'author_name': AUTHOR_ID_TO_NAME.get(c.get('author_id'), 'Unknown'),
            'ml_generated': c['ml']
        }
        for c in obj.get('classifications', [])
    ]

    # Mark the comments generated by bots
    comments = [
        {
            'author_id': c['author_id'],
            'text': c['text'],
            'created_at': c['created_at'],
            'bot_generated': c['bot'],
            'author_name': AUTHOR_ID_TO_NAME.get(c['author_id'], 'Unknown')
        }
        for c in obj.get('comments', [])
    ]

    cleaned_obj = {
        'id': obj['id'],
        'RA/Dec': f"{obj['ra']}, {obj['dec']}",
        'redshift': redshift_value,
        'tns_name': obj.get('tns_name', 'N/A'),
        'classifications': classifications,
        'comments': comments,
        'groups': [group['name'] for group in obj['groups']],
        'luminosity_distance': obj.get('luminosity_distance', 'N/A'),
        'thumbnails': [thumbnail['public_url'] for thumbnail in obj.get('thumbnails', [])]
    }

    return cleaned_obj

# Clean the data for all objects
cleaned_objects = [clean_data(obj) for obj in data['data']['sources']]

# Function to create a prompt for Ollama
def create_prompt(obj):
    classifications_str = ', '.join([
        f"{c['classification']} (ML-generated)" if c['ml_generated'] else f"{c['classification']} by {c['author_name']}"
        for c in obj['classifications']
    ]) if obj['classifications'] else 'None'

    comments_str = ', '.join([
        f"{comment['text']} (Bot-generated)" if comment['bot_generated'] else f"{comment['text']} by {comment['author_name']}"
        for comment in obj['comments'] if comment['text']
    ]) if obj['comments'] else 'None'

    data_block = f"""
    Object Name: {obj['tns_name'] or 'N/A'}
    Position: {obj['RA/Dec']}
    Redshift: {obj['redshift'] or 'None'}
    Luminosity Distance: {obj['luminosity_distance'] or 'N/A'}
    Classification: {classifications_str}
    Key Comments: {comments_str}
    Thumbnail URLs: {', '.join(obj['thumbnails']) if obj['thumbnails'] else 'None'}
    """

    prompt = f"""
    Summarize the structured data from the ZTF alert stream for the date 16/05/2021.
    Provide a concise, formal overview suitable for experienced astronomers, focusing only on scientifically relevant details. 
    The summary should include the following sections:

    Transient Details:
        Name of transient.
        Sky position (RA/Dec) with appropriate precision.
        Latest redshift value (state "None" if unavailable).
        Luminosity distance in megaparsecs (state "N/A" if unavailable).
    Classifications:
        List all unique classifications of the transients.
        Clearly indicate any classifications derived from automated machine learning models.
    User Comments:
        Summarize pertinent user comments, grouped by author.
        Indicate if comments are bot-generated.
    Spectroscopic Data:
        Details of any spectra obtained, including instruments used and observation timestamps.
    Visual Inspection:
        Provide all available thumbnail URLs for visual inspection of transients.
    Additional Requirements:
        Use a structured and formal tone.
        Avoid providing unnecessary background explanations or basic astronomical concepts.
        If any data is missing, explicitly state it, e.g., “No classifications available” or “No spectra available.”
        Do not include personal opinions or speculative interpretations.
        
    You must not return the input data in the summary.
    Input Data: {data_block}
    """
    return prompt

# Function to generate a summary using Ollama
def generate_summary(prompt):
    try:
        response = ollama.chat(
            model="llama3.2:1b",
            messages=[{"role": "user", "content": prompt}],
        )
        return response['message']['content']
    except Exception as e:
        return f"Error generating summary: {e}"

# Initialisation of the summaries set in session_state
if "summaries" not in st.session_state:
    st.session_state.summaries = {}

# Streamlit interface
st.title("Daily Summaries of Astronomical Actions")
st.write("Select a group and an object by TNS Name to view the summary.")

# Add dropdown to select a group
selected_group = st.selectbox("Select a group", unique_groups)

# Filter objects based on selected group
filtered_objects = [obj for obj in cleaned_objects if selected_group in obj['groups']]

# Add dropdown to select an object by TNS Name
tns_names = [obj['tns_name'] for obj in filtered_objects if obj['tns_name'] != 'N/A']
selected_tns_name = st.selectbox("Select an object by TNS Name", tns_names)

validate_button = st.button("Generate Summary")

import time

# Generate the summary if the button is clicked
if validate_button:
    selected_obj = next((obj for obj in filtered_objects if obj['tns_name'] == selected_tns_name), None)
    if selected_obj:
        with st.spinner("Generating summary..."):
            start = time.time()
            prompt = create_prompt(selected_obj)
            summary = generate_summary(prompt)

            end = time.time()
            # Add or update the summary in the session_state dictionary
            st.session_state.summaries[selected_tns_name] = f"Summary for {selected_tns_name}:\n{summary}"
            st.write(f"Summary generated in {end - start:.2f} seconds.")
            st.success("Summary generated successfully!")
    else:
        st.write("Selected object not found.")

if st.session_state.summaries:
    st.subheader("Previously Generated Summaries")
    summary_titles = list(st.session_state.summaries.keys())  # Get all object names
    selected_summary_title = st.selectbox("Select a summary to view", summary_titles)
    # Display the selected summary
    selected_summary = st.session_state.summaries[selected_summary_title]
    display_summary = st.button("Display Selected Summary")
    if display_summary:
        st.write(selected_summary)
        stop_display = st.button("Stop Display")
        if stop_display:
            st.empty()
    # display all summaries
    display_all = st.button("Display All Summaries")
    if display_all:
        st.subheader("All Summaries")
        for resume in st.session_state.summaries:
            st.write(st.session_state.summaries[resume])
            st.markdown("---")
            st.write("\n")
            st.markdown("---")